{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "52774b798c40528f530de7657fd1851e18ea3fd46ccdf10ced65da4d8da447ac"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TF-IDF\n",
    "\n",
    "TF-IDF is one of the best known methods for text focused search. In this notebook we'll explore how it works, and implement it in Python. Let's start by creating a few example sentences."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"purple is the best city in the forest\".split()\n",
    "b = \"there is an art to getting your way and throwing bananas on to the street is not it\".split()\n",
    "c = \"it is not often you find soggy bananas on the street\".split()"
   ]
  },
  {
   "source": [
    "To calculate the TF-IDF for a given word (the query) and a sentence (the document), we calculate the **T**erm **F**requency (**TF**), and the **I**nverse **D**ocument **F**requency (**IDF**)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# we'll merge all docs into a list of lists for easier calculations below\n",
    "docs = [a, b, c]\n",
    "\n",
    "def tfidf(word, sentence):\n",
    "    # term frequency\n",
    "    tf = sentence.count(word) / len(sentence)\n",
    "    # inverse document frequency\n",
    "    idf = np.log10(len(docs) / sum([1 for doc in docs if word in doc]))\n",
    "    return round(tf*idf, 4)"
   ]
  },
  {
   "source": [
    "Let's calculate the score between each sentence *a*, *b*, and *c* - against the word *'forest'*."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0596"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "tfidf('forest', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tfidf('forest', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tfidf('forest', c)"
   ]
  },
  {
   "source": [
    "We would expect sentence *a* to score highest (as the only sentence that contains the word), and that is what we see above.\n",
    "\n",
    "---\n",
    "\n",
    "## Vectors\n",
    "\n",
    "Now, calculating TF-IDF vectors is slightly different. It requires that we compute the TF-IDF score for all words within our document vocabulary (a set of all words across all documents), and we compute that for each sentence (document) - producing document-specific TF-IDF vectors.\n",
    "\n",
    "Let's start by creating a vocabulary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(a+b+c)"
   ]
  },
  {
   "source": [
    "And now we create the vectors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0596, 0.0, 0.0, 0.0, 0.0596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0596, 0.0, 0.0, 0.0596, 0.0, 0.0596, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# initialize vectors\n",
    "vec_a = []\n",
    "vec_b = []\n",
    "vec_c = []\n",
    "\n",
    "for word in vocab:\n",
    "    vec_a.append(tfidf(word, a))\n",
    "    vec_b.append(tfidf(word, b))\n",
    "    vec_c.append(tfidf(word, c))\n",
    "\n",
    "print(vec_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.0, 0.0, 0.0265, 0.0265, 0.0098, 0.0, 0.053, 0.0, 0.0265, 0.0265, 0.0, 0.0, 0.0, 0.0098, 0.0098, 0.0098, 0.0, 0.0098, 0.0, 0.0265, 0.0265, 0.0, 0.0265, 0.0, 0.0265]\n"
     ]
    }
   ],
   "source": [
    "print(vec_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.0434, 0.0, 0.0, 0.0, 0.016, 0.0434, 0.0, 0.0, 0.0, 0.0, 0.0434, 0.0, 0.0434, 0.016, 0.016, 0.016, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(vec_c)"
   ]
  }
 ]
}